{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "R7kUl9ceYXnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZywfvb6Ysfh",
        "outputId": "915eae40-9bcf-4cb9-f894-e2e92d37dea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (886 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.5/886.5 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cu118 torch-scatter-2.1.2+pt20cu118 torch-sparse-0.6.18+pt20cu118 torch-spline-conv-1.2.2+pt20cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from skimage.segmentation import slic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E18hGucYZO3",
        "outputId": "2c596e7a-d5e7-4d19-b824-6040027c6650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyutxkqNPcQs",
        "outputId": "5ca979d1-9480-486b-e9f8-4494a7aeb44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjrbFZBgR0Bu",
        "outputId": "8e38cf1e-8d85-49a1-99a3-e6e2191b8a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images --force\n",
        "!unzip -oq breast-histopathology-images.zip -d /content/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rM5S4ELWoJ5",
        "outputId": "540bc75b-2295-4406-a1df-33094f6c8a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images\n",
            "License(s): CC0-1.0\n",
            "Downloading breast-histopathology-images.zip to /content\n",
            " 98% 3.03G/3.10G [00:16<00:01, 38.6MB/s]\n",
            "100% 3.10G/3.10G [00:17<00:00, 195MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/IDC_regular_ps50_idx5/0 | head\n",
        "!ls /content/IDC_regular_ps50_idx5/1 | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NFSsd4IXK_o",
        "outputId": "9da6bd1e-f803-44be-d3cf-d5f5a0b5043f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10257\n",
            "10258\n",
            "10261\n",
            "10264\n",
            "10273\n",
            "10277\n",
            "10278\n",
            "10279\n",
            "10291\n",
            "10302\n",
            "10253\n",
            "10254\n",
            "10255\n",
            "10256\n",
            "10257\n",
            "10258\n",
            "10259\n",
            "10260\n",
            "10261\n",
            "10262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "png_files = glob.glob(\"/content/IDC_regular_ps50_idx5/*/*/*.png\")\n",
        "print(f\"🖼️ Total PNG files found: {len(png_files)}\")\n",
        "print(\"Example files:\")\n",
        "print(png_files[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K3hf4JUXgBS",
        "outputId": "9421a2cc-a9d7-4536-9f24-ccf7e3c6a297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🖼️ Total PNG files found: 277524\n",
            "Example files:\n",
            "['/content/IDC_regular_ps50_idx5/10288/1/10288_idx5_x2101_y151_class1.png', '/content/IDC_regular_ps50_idx5/10288/1/10288_idx5_x1901_y301_class1.png', '/content/IDC_regular_ps50_idx5/10288/1/10288_idx5_x2051_y151_class1.png', '/content/IDC_regular_ps50_idx5/10288/1/10288_idx5_x2201_y401_class1.png', '/content/IDC_regular_ps50_idx5/10288/1/10288_idx5_x1951_y251_class1.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision torchaudio torch-geometric scikit-image\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from skimage.segmentation import slic\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.metrics import f1_score, cohen_kappa_score, roc_auc_score, accuracy_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31SH4s-uZBQd",
        "outputId": "a67f1367-1019-4381-f9b8-c2d5cae92f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_graph(image_path, label, n_segments=30):\n",
        "\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\").resize((100, 100))\n",
        "        image_np = np.array(image)\n",
        "        segments = slic(image_np, n_segments=n_segments, compactness=10, start_label=0)\n",
        "        num_nodes = segments.max() + 1\n",
        "\n",
        "        features = np.zeros((num_nodes, 3))\n",
        "        for i in range(num_nodes):\n",
        "            mask = segments == i\n",
        "            features[i] = image_np[mask].mean(axis=0) / 255.0\n",
        "\n",
        "        edges = set()\n",
        "        for i in range(segments.shape[0] - 1):\n",
        "            for j in range(segments.shape[1] - 1):\n",
        "                current = segments[i, j]\n",
        "                for ni, nj in [(i+1, j), (i, j+1)]:\n",
        "                    neighbor = segments[ni, nj]\n",
        "                    if current != neighbor:\n",
        "                        edges.add((current, neighbor))\n",
        "                        edges.add((neighbor, current))\n",
        "\n",
        "        edge_index = torch.tensor(list(edges), dtype=torch.long).t().contiguous()\n",
        "        x = torch.tensor(features, dtype=torch.float)\n",
        "        y = torch.tensor([label], dtype=torch.long)\n",
        "        return Data(x=x, edge_index=edge_index, y=y)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in {image_path}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Bgnz3LJKZkjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_graph_dataset(dataset_dir, limit_per_class=250):\n",
        "    data = {0: [], 1: []}\n",
        "\n",
        "    for patient_folder in os.listdir(dataset_dir):\n",
        "        patient_path = os.path.join(dataset_dir, patient_folder)\n",
        "        if not os.path.isdir(patient_path):\n",
        "            continue\n",
        "\n",
        "        for class_label in ['0', '1']:\n",
        "            class_path = os.path.join(patient_path, class_label)\n",
        "            if not os.path.exists(class_path):\n",
        "                continue\n",
        "\n",
        "            for fname in os.listdir(class_path):\n",
        "                if fname.endswith(\".png\") and len(data[int(class_label)]) < limit_per_class:\n",
        "                    fpath = os.path.join(class_path, fname)\n",
        "                    graph = create_graph(fpath, int(class_label))\n",
        "                    if graph:\n",
        "                        data[int(class_label)].append(graph)\n",
        "\n",
        "    return data[0] + data[1]\n"
      ],
      "metadata": {
        "id": "A11n2jHIZoe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/IDC_regular_ps50_idx5\"\n",
        "dataset = load_graph_dataset(dataset_path, limit_per_class=1000)\n",
        "print(f\"✅ Total graphs loaded: {len(dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQRgMrZTahYo",
        "outputId": "6e02dcb0-0919-41dc-8fd6-4800076251cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Total graphs loaded: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_val, test = train_test_split(dataset, test_size=0.2, stratify=[d.y.item() for d in dataset], random_state=42)\n",
        "train, val = train_test_split(train_val, test_size=0.25, stratify=[d.y.item() for d in train_val], random_state=42)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val, batch_size=32)\n",
        "test_loader = DataLoader(test, batch_size=32)\n",
        "\n",
        "print(f\"🧪 Train: {len(train)} | Val: {len(val)} | Test: {len(test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9unUf-Zxatex",
        "outputId": "4a936c6e-9f2f-4a12-c8f3-4d6ee0b74ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 Train: 1200 | Val: 400 | Test: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index).relu()\n",
        "        x = self.conv3(x, edge_index).relu()\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return self.lin(x)"
      ],
      "metadata": {
        "id": "1xfFApzEauf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(in_channels=3, hidden_channels=64, out_channels=2).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index, batch.batch)\n",
        "        loss = loss_fn(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index, batch.batch)\n",
        "            pred = out.argmax(dim=1)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            labels.extend(batch.y.cpu().numpy())\n",
        "    return preds, labels\n",
        "for epoch in range(1, 51):\n",
        "    loss = train()\n",
        "    val_preds, val_labels = evaluate(val_loader)\n",
        "    acc = accuracy_score(val_labels, val_preds)\n",
        "    print(f\"📉 Epoch {epoch} | Loss: {loss:.4f} | Val Acc: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahnKBNJSav5X",
        "outputId": "e81bd6b6-3154-4abb-8dbe-3731ab9c7a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📉 Epoch 1 | Loss: 0.6917 | Val Acc: 0.5000\n",
            "📉 Epoch 2 | Loss: 0.6887 | Val Acc: 0.6925\n",
            "📉 Epoch 3 | Loss: 0.6816 | Val Acc: 0.5000\n",
            "📉 Epoch 4 | Loss: 0.6731 | Val Acc: 0.6900\n",
            "📉 Epoch 5 | Loss: 0.6439 | Val Acc: 0.7075\n",
            "📉 Epoch 6 | Loss: 0.6092 | Val Acc: 0.7250\n",
            "📉 Epoch 7 | Loss: 0.5883 | Val Acc: 0.7400\n",
            "📉 Epoch 8 | Loss: 0.5691 | Val Acc: 0.7475\n",
            "📉 Epoch 9 | Loss: 0.5670 | Val Acc: 0.7450\n",
            "📉 Epoch 10 | Loss: 0.5610 | Val Acc: 0.7525\n",
            "📉 Epoch 11 | Loss: 0.5487 | Val Acc: 0.7600\n",
            "📉 Epoch 12 | Loss: 0.5393 | Val Acc: 0.7650\n",
            "📉 Epoch 13 | Loss: 0.5377 | Val Acc: 0.7575\n",
            "📉 Epoch 14 | Loss: 0.5372 | Val Acc: 0.7575\n",
            "📉 Epoch 15 | Loss: 0.5355 | Val Acc: 0.7600\n",
            "📉 Epoch 16 | Loss: 0.5289 | Val Acc: 0.7675\n",
            "📉 Epoch 17 | Loss: 0.5241 | Val Acc: 0.7625\n",
            "📉 Epoch 18 | Loss: 0.5230 | Val Acc: 0.7725\n",
            "📉 Epoch 19 | Loss: 0.5276 | Val Acc: 0.7575\n",
            "📉 Epoch 20 | Loss: 0.5195 | Val Acc: 0.7475\n",
            "📉 Epoch 21 | Loss: 0.5114 | Val Acc: 0.7625\n",
            "📉 Epoch 22 | Loss: 0.5040 | Val Acc: 0.7325\n",
            "📉 Epoch 23 | Loss: 0.5046 | Val Acc: 0.7700\n",
            "📉 Epoch 24 | Loss: 0.5007 | Val Acc: 0.7750\n",
            "📉 Epoch 25 | Loss: 0.5120 | Val Acc: 0.7475\n",
            "📉 Epoch 26 | Loss: 0.4997 | Val Acc: 0.7775\n",
            "📉 Epoch 27 | Loss: 0.5170 | Val Acc: 0.6950\n",
            "📉 Epoch 28 | Loss: 0.4956 | Val Acc: 0.7800\n",
            "📉 Epoch 29 | Loss: 0.4970 | Val Acc: 0.7950\n",
            "📉 Epoch 30 | Loss: 0.4795 | Val Acc: 0.7600\n",
            "📉 Epoch 31 | Loss: 0.4813 | Val Acc: 0.7525\n",
            "📉 Epoch 32 | Loss: 0.4773 | Val Acc: 0.7700\n",
            "📉 Epoch 33 | Loss: 0.4764 | Val Acc: 0.7725\n",
            "📉 Epoch 34 | Loss: 0.4751 | Val Acc: 0.7850\n",
            "📉 Epoch 35 | Loss: 0.4616 | Val Acc: 0.7975\n",
            "📉 Epoch 36 | Loss: 0.4679 | Val Acc: 0.7650\n",
            "📉 Epoch 37 | Loss: 0.4643 | Val Acc: 0.7675\n",
            "📉 Epoch 38 | Loss: 0.4768 | Val Acc: 0.8000\n",
            "📉 Epoch 39 | Loss: 0.4594 | Val Acc: 0.7975\n",
            "📉 Epoch 40 | Loss: 0.4646 | Val Acc: 0.7650\n",
            "📉 Epoch 41 | Loss: 0.4767 | Val Acc: 0.7500\n",
            "📉 Epoch 42 | Loss: 0.4688 | Val Acc: 0.7500\n",
            "📉 Epoch 43 | Loss: 0.4527 | Val Acc: 0.7725\n",
            "📉 Epoch 44 | Loss: 0.4494 | Val Acc: 0.8025\n",
            "📉 Epoch 45 | Loss: 0.4655 | Val Acc: 0.8000\n",
            "📉 Epoch 46 | Loss: 0.4481 | Val Acc: 0.8050\n",
            "📉 Epoch 47 | Loss: 0.4625 | Val Acc: 0.7950\n",
            "📉 Epoch 48 | Loss: 0.4508 | Val Acc: 0.8100\n",
            "📉 Epoch 49 | Loss: 0.4532 | Val Acc: 0.8000\n",
            "📉 Epoch 50 | Loss: 0.4389 | Val Acc: 0.8150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        ")\n",
        "\n",
        "test_preds, test_labels, test_probs = evaluate_with_probs(test_loader)\n",
        "print(\"\\n📊 Final Test Metrics:\")\n",
        "print(f\"✔️ Test Accuracy       : {accuracy_score(test_labels, test_preds):.4f}\")\n",
        "print(f\"✔️ Test Macro F1       : {f1_score(test_labels, test_preds, average='macro'):.4f}\")\n",
        "print(f\"✔️ Test Weighted F1    : {f1_score(test_labels, test_preds, average='weighted'):.4f}\")\n",
        "print(f\"✔️ Cohen's Kappa       : {cohen_kappa_score(test_labels, test_preds):.4f}\")\n",
        "print(f\"✔️ Test AUC (Macro)    : {roc_auc_score(test_labels, test_probs[:, 1]):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4xGSaa_azWm",
        "outputId": "d6147676-a841-42f7-e519-699fcab7172f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Final Test Metrics:\n",
            "✔️ Test Accuracy       : 0.8125\n",
            "✔️ Test Macro F1       : 0.8125\n",
            "✔️ Test Weighted F1    : 0.8125\n",
            "✔️ Cohen's Kappa       : 0.6250\n",
            "✔️ Test AUC (Macro)    : 0.8988\n"
          ]
        }
      ]
    }
  ]
}