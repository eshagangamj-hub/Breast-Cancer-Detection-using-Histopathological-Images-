{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub --quiet\n",
        "!pip install torch torchvision torchaudio --upgrade --quiet\n",
        "!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html --quiet\n",
        "!pip install scikit-learn opencv-python scikit-image matplotlib --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpvvq3uOTS1Q",
        "outputId": "4032f0e8-b88f-416e-8c42-ab0a7fb9eb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.0/494.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.9/750.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqW8yWZtFOkE",
        "outputId": "850acec3-82ea-4b5d-826a-0e0fa5802466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Dataset loaded from: /kaggle/input/breast-histopathology-images\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "dataset_dir = kagglehub.dataset_download(\"paultimothymooney/breast-histopathology-images\")\n",
        "print(\"📁 Dataset loaded from:\", dataset_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import random\n",
        "\n",
        "def collect_image_paths(dataset_dir, max_patients=10, max_per_class=100):\n",
        "    image_paths = []\n",
        "    patient_dirs = sorted(os.listdir(dataset_dir))[:max_patients]\n",
        "\n",
        "    for patient_id in patient_dirs:\n",
        "        patient_path = os.path.join(dataset_dir, patient_id)\n",
        "        for class_label in ['0', '1']:\n",
        "            class_path = os.path.join(patient_path, class_label)\n",
        "            if os.path.exists(class_path):\n",
        "                images = glob(os.path.join(class_path, \"*.png\"))\n",
        "                selected = random.sample(images, min(max_per_class, len(images)))\n",
        "                image_paths += [(img_path, int(class_label)) for img_path in selected]\n",
        "    return image_paths\n",
        "\n",
        "image_data = collect_image_paths(dataset_dir, max_patients=10, max_per_class=100)\n",
        "print(\"📊 Total labeled images:\", len(image_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvb-ugIitXZo",
        "outputId": "775bf70b-b442-4cda-cb67-161d7a80028c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Total labeled images: 1824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from skimage.io import imread\n",
        "from skimage.segmentation import slic\n",
        "from skimage.color import rgb2lab\n",
        "import numpy as np\n",
        "\n",
        "def convert_image_to_graph(image_path, label, num_segments=75):\n",
        "    image = imread(image_path)\n",
        "    if image.shape[-1] == 4:\n",
        "        image = image[:, :, :3]\n",
        "    segments = slic(image, n_segments=num_segments, compactness=10, start_label=0)\n",
        "    image_lab = rgb2lab(image)\n",
        "    num_nodes = segments.max() + 1\n",
        "\n",
        "    node_features = np.zeros((num_nodes, 3))\n",
        "    for i in range(num_nodes):\n",
        "        mask = segments == i\n",
        "        node_features[i] = image_lab[mask].mean(axis=0)\n",
        "\n",
        "    edge_set = set()\n",
        "    H, W = segments.shape\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            src = segments[i, j]\n",
        "            for dx, dy in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
        "                ni, nj = i+dx, j+dy\n",
        "                if 0 <= ni < H and 0 <= nj < W:\n",
        "                    dst = segments[ni, nj]\n",
        "                    if src != dst:\n",
        "                        edge_set.add((src, dst))\n",
        "\n",
        "    edge_index = torch.tensor(list(edge_set), dtype=torch.long).t().contiguous()\n",
        "    x = torch.tensor(node_features, dtype=torch.float)\n",
        "    y = torch.tensor([label], dtype=torch.long)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index, y=y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0awY8GL-xoFA",
        "outputId": "dcfb3567-aa02-4910-fbbd-06215cc41c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = image_data[:1000]  # increase dataset\n",
        "graph_data = [convert_image_to_graph(p, l, num_segments=60) for p, l in image_data]\n"
      ],
      "metadata": {
        "id": "HwAXb0catkRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_data = [convert_image_to_graph(p, l, num_segments=60) for p, l in image_data[:1000]]\n"
      ],
      "metadata": {
        "id": "anp0kPEnylH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "graph_data = [convert_image_to_graph(p, l, num_segments=60) for p, l in tqdm(image_data[:1000])]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU7G31asymZM",
        "outputId": "e9795bfb-27e0-4a3a-9ea4-77a01660475f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:04<00:00, 46.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image --quiet\n"
      ],
      "metadata": {
        "id": "qmzH1iSptrpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "total = len(graph_data)\n",
        "train_len = int(0.7 * total)\n",
        "val_len = int(0.15 * total)\n",
        "test_len = total - train_len - val_len\n",
        "\n",
        "train_set, val_set, test_set = random_split(graph_data, [train_len, val_len, test_len])\n",
        "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=8)\n",
        "test_loader = DataLoader(test_set, batch_size=8)\n",
        "\n",
        "print(f\"📊 Dataset sizes → Train: {train_len}, Val: {val_len}, Test: {test_len}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V4OWSG2uD34",
        "outputId": "190a92e3-e60e-4dc8-ec54-f8e395a07c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Dataset sizes → Train: 140, Val: 30, Test: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, BatchNorm, global_mean_pool\n",
        "\n",
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.dropout(F.relu(self.bn1(self.conv1(x, edge_index))), p=0.3, training=self.training)\n",
        "        x = F.dropout(F.relu(self.bn2(self.conv2(x, edge_index))), p=0.3, training=self.training)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return x\n",
        "\n",
        "class AGCLModel(nn.Module):\n",
        "    def __init__(self, in_channels=3, hidden_dim=64, proj_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = GCNEncoder(in_channels, hidden_dim)\n",
        "        self.proj_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, proj_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(proj_dim, proj_dim)\n",
        "        )\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(6, 32), nn.ReLU(), nn.Linear(32, 1), nn.Sigmoid()\n",
        "        )\n",
        "        self.classifier = nn.Linear(hidden_dim, 2)\n",
        "\n",
        "    def forward(self, data, mask_edges=False):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        if mask_edges and self.training:\n",
        "            row, col = edge_index\n",
        "            edge_feat = torch.cat([x[row], x[col]], dim=1)\n",
        "            edge_prob = self.edge_mlp(edge_feat).squeeze()\n",
        "            keep = edge_prob.bernoulli().bool()\n",
        "            edge_index = edge_index[:, keep]\n",
        "\n",
        "        z = self.encoder(x, edge_index, batch)\n",
        "        proj = self.proj_head(z)\n",
        "        out = self.classifier(z)\n",
        "        return proj, out\n"
      ],
      "metadata": {
        "id": "sCh0-IxxuTU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss(z1, z2, temperature=0.5):\n",
        "    z1 = F.normalize(z1, dim=1)\n",
        "    z2 = F.normalize(z2, dim=1)\n",
        "    sim = torch.mm(z1, z2.T) / temperature\n",
        "    labels = torch.arange(z1.size(0)).to(z1.device)\n",
        "    return F.cross_entropy(sim, labels)\n"
      ],
      "metadata": {
        "id": "lB9aMu3uu0AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = AGCLModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        z1, out1 = model(batch, mask_edges=False)\n",
        "        z2, _ = model(batch, mask_edges=True)\n",
        "\n",
        "        loss_cls = loss_fn(out1, batch.y)\n",
        "        loss_contrast = contrastive_loss(z1, z2)\n",
        "        loss = loss_cls + 0.5 * loss_contrast\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, label=\"Test\"):\n",
        "    model.eval()\n",
        "    y_true, y_pred, y_prob = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            _, out = model(batch)\n",
        "            probs = F.softmax(out, dim=1)\n",
        "            preds = probs.argmax(dim=1)\n",
        "\n",
        "            y_true.extend(batch.y.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_prob.extend(probs[:,1].cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_prob)\n",
        "    print(f\"📈 {label} → Acc: {acc:.4f} | F1-macro: {f1_macro:.4f} | F1-weighted: {f1_weighted:.4f} | Kappa: {kappa:.4f} | AUC: {auc:.4f}\")\n",
        "    return acc, f1_macro, f1_weighted, kappa, auc\n"
      ],
      "metadata": {
        "id": "Qz60NyOnu-aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 21):\n",
        "    loss = train_epoch(model, train_loader, optimizer)\n",
        "    print(f\"Epoch {epoch:02d} | 🔧 Loss: {loss:.4f}\")\n",
        "    if epoch % 5 == 0:\n",
        "        evaluate(model, val_loader, \"Validation\")\n",
        "\n",
        "print(\"✅ Final Evaluation on Test Set:\")\n",
        "evaluate(model, test_loader, \"Test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efmklhMBy7oV",
        "outputId": "40c3d959-3ead-4e73-cebb-2b45cfbd4ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | 🔧 Loss: 0.6177\n",
            "Epoch 02 | 🔧 Loss: 0.6793\n",
            "Epoch 03 | 🔧 Loss: 0.5815\n",
            "Epoch 04 | 🔧 Loss: 0.6132\n",
            "Epoch 05 | 🔧 Loss: 0.7278\n",
            "📈 Validation → Acc: 0.9000 | F1-macro: 0.8330 | F1-weighted: 0.8894 | Kappa: 0.6715 | AUC: 0.8634\n",
            "Epoch 06 | 🔧 Loss: 0.6537\n",
            "Epoch 07 | 🔧 Loss: 0.6389\n",
            "Epoch 08 | 🔧 Loss: 0.6001\n",
            "Epoch 09 | 🔧 Loss: 0.6684\n",
            "Epoch 10 | 🔧 Loss: 0.5859\n",
            "📈 Validation → Acc: 0.8667 | F1-macro: 0.7600 | F1-weighted: 0.8453 | Kappa: 0.5349 | AUC: 0.8820\n",
            "Epoch 11 | 🔧 Loss: 0.6721\n",
            "Epoch 12 | 🔧 Loss: 0.6890\n",
            "Epoch 13 | 🔧 Loss: 0.6529\n",
            "Epoch 14 | 🔧 Loss: 0.6116\n",
            "Epoch 15 | 🔧 Loss: 0.6966\n",
            "📈 Validation → Acc: 0.9333 | F1-macro: 0.9068 | F1-weighted: 0.9333 | Kappa: 0.8137 | AUC: 0.8758\n",
            "Epoch 16 | 🔧 Loss: 0.6715\n",
            "Epoch 17 | 🔧 Loss: 0.6570\n",
            "Epoch 18 | 🔧 Loss: 0.5632\n",
            "Epoch 19 | 🔧 Loss: 0.6472\n",
            "Epoch 20 | 🔧 Loss: 0.6389\n",
            "📈 Validation → Acc: 0.9000 | F1-macro: 0.8527 | F1-weighted: 0.8972 | Kappa: 0.7059 | AUC: 0.8820\n",
            "✅ Final Evaluation on Test Set:\n",
            "📈 Test → Acc: 0.9000 | F1-macro: 0.8901 | F1-weighted: 0.8989 | Kappa: 0.7805 | AUC: 0.9856\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9,\n",
              " 0.8901098901098901,\n",
              " 0.898901098901099,\n",
              " np.float64(0.7804878048780488),\n",
              " np.float64(0.9856459330143541))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}